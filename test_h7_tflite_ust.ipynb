{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import resampy\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from metrics import evaluate, micro_averaged_auprc, macro_averaged_auprc\n",
    "import oyaml as yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_from_tflite(cmsis_mels, tflite_model, input_index, output_index):\n",
    "    \n",
    "    predictions = []\n",
    "    #predictions per frame   \n",
    "    for idx in range(cmsis_mels.shape[0]):   #Ex of shape: (91, 64, 51)\n",
    "        x = np.array(cmsis_mels[idx])[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "        tflite_model.set_tensor(input_index, x)\n",
    "        tflite_model.invoke()\n",
    "        output = tflite_model.get_tensor(output_index)\n",
    "        predictions.append(output)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_output(output_path, test_file_list, y_pred, taxonomy):\n",
    "    \n",
    "    coarse_fine_labels = [[\"{}-{}_{}\".format(coarse_id, fine_id, fine_label)\n",
    "                           for fine_id, fine_label in fine_dict.items()]\n",
    "                          for coarse_id, fine_dict in taxonomy['fine'].items()]\n",
    "        \n",
    "    full_fine_target_labels = [fine_label for fine_list in coarse_fine_labels\n",
    "                               for fine_label in fine_list]\n",
    "        \n",
    "    coarse_target_labels = [\"_\".join([str(k), v])\n",
    "                            for k, v in taxonomy['coarse'].items()]\n",
    "        \n",
    "    with open(output_path, 'w') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "\n",
    "        # Write fields\n",
    "        fields = [\"audio_filename\"] + full_fine_target_labels + coarse_target_labels\n",
    "        csvwriter.writerow(fields)\n",
    "\n",
    "        # Write results for each file to CSV\n",
    "        for filename, y, in zip(test_file_list, y_pred):\n",
    "            filename = os.path.basename(filename.replace('npz', 'wav'))\n",
    "            row = [filename]\n",
    "\n",
    "            # Add placeholder values for fine level\n",
    "            row += [0.0 for _ in range(len(full_fine_target_labels))]\n",
    "            # Add coarse level labels\n",
    "            row += list(y)\n",
    "\n",
    "            csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cmsis_mels(file_list, taxonomy, output_path, model_path):\n",
    "    \n",
    "    y_pred_mean = []\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path) \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_shape = input_details[0]['shape'][1:]\n",
    "    output_shape = output_details[0]['shape'][1:]\n",
    "    input_index = input_details[0]['index']\n",
    "    output_index = output_details[0]['index']\n",
    "\n",
    "#     print(\"== Input details ==\")\n",
    "#     print(interpreter.get_input_details()[0])\n",
    "#     print(\"type:\", input_details[0]['dtype'])\n",
    "#     print(\"\\n== Output details ==\")\n",
    "#     print(interpreter.get_output_details()[0])\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    for file in file_list:\n",
    "        cmsis_mels = np.load(file)['db_mels']\n",
    "        output = get_output_from_tflite(cmsis_mels, interpreter, input_index, output_index)\n",
    "\n",
    "        #coarse classes of sonyc = 8\n",
    "        pred_frame = np.array(output).reshape(-1, 8)\n",
    "        y_pred_mean.append(pred_frame.mean(axis=0).tolist())\n",
    "    \n",
    "    write_to_output(output_path, file_list, y_pred_mean, taxonomy)\n",
    "    assert os.path.exists(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(prediction_path, annotation_path, yaml_path, mode='coarse'):\n",
    "    \n",
    "    metrics = {\n",
    "        'coarse': {}\n",
    "    }\n",
    "\n",
    "    df_dict = evaluate(prediction_path,\n",
    "                       annotation_path,\n",
    "                       yaml_path,\n",
    "                       mode)\n",
    "\n",
    "    micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "    macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)    \n",
    "\n",
    "     # Get index of first threshold that is at least 0.5\n",
    "    thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
    "\n",
    "    metrics[mode][\"micro_auprc\"] = micro_auprc\n",
    "    metrics[mode][\"micro_f1\"] = eval_df[\"F\"][thresh_0pt5_idx]\n",
    "    metrics[mode][\"macro_auprc\"] = macro_auprc\n",
    "\n",
    "    print(\"{} level evaluation:\".format(mode.capitalize()))\n",
    "    print(\"======================\")\n",
    "    print(\" * Micro AUPRC:           {}\".format(metrics[mode][\"micro_auprc\"]))\n",
    "    print(\" * Micro F1-score (@0.5): {}\".format(metrics[mode][\"micro_f1\"]))\n",
    "    print(\" * Macro AUPRC:           {}\".format(metrics[mode][\"macro_auprc\"]))\n",
    "    print(\" * Coarse Tag AUPRC:\")\n",
    "\n",
    "    metrics[mode][\"class_auprc\"] = {}\n",
    "    for coarse_id, auprc in class_auprc.items():\n",
    "        coarse_name = taxonomy['coarse'][int(coarse_id)]\n",
    "        metrics[mode][\"class_auprc\"][coarse_name] = auprc\n",
    "        print(\"      - {}: {}\".format(coarse_name, auprc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    TEST_DIR = os.path.dirname(os.path.realpath('__file__'))\n",
    "    TFLITE_MODELS_DIR = os.path.join(TEST_DIR, 'tflite_models')\n",
    "    MODEL_PATH = os.path.join(TFLITE_MODELS_DIR, 'cmsis_mels_full_quantized_default_float32.tflite')\n",
    "    OUTPUT_DIR = os.path.join(TEST_DIR, 'output/sonyc_ust/cmsis_val')\n",
    "        \n",
    "    if not os.path.isdir(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "    DATA_DIR = '/beegfs/dr2915/sonyc_ust'\n",
    "    annotation_path = os.path.join(DATA_DIR, 'annotations.csv')\n",
    "    yaml_path = os.path.join(DATA_DIR, 'dcase-ust-taxonomy.yaml')\n",
    "    test_data = glob.glob(os.path.join(DATA_DIR, 'db_mels/validate/*.npz'))[0:20]\n",
    "    prediction_path = os.path.join(OUTPUT_DIR, 'predictions.csv')\n",
    "    output_path = os.path.join(OUTPUT_DIR, 'output_mean.csv')\n",
    "\n",
    "    with open(yaml_path) as f:\n",
    "        taxonomy = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    process_cmsis_mels(test_data, taxonomy, output_path, model_path=MODEL_PATH)\n",
    "    #evaluate_all(output_path, annotation_path, yaml_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
